{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c2ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c532d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7d05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2a8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965f8348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021a9d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63345d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets look at one review\n",
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346ff471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f3c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaning\n",
    "\n",
    "# Sample 10000 rows : working on only 10,000 rows to train easily.\n",
    "# Remove html tags\n",
    "# Remove special characters\n",
    "# Convert to lower case\n",
    "# Removing Stop Words : words like \"and\" , \"is , \"are\" , etc\n",
    "# Stemming : fetch only the root word and eliminate all other words that are similar to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad464bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ebc414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 15390 to 37479\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     10000 non-null  object\n",
      " 1   sentiment  10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b85bdfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'].replace({'positive' : 1 , 'negative' : 0} , inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "152d5d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15390</th>\n",
       "      <td>This is simply a good ole fashioned western..n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>This has to be one of the most beautiful, movi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27425</th>\n",
       "      <td>Bring Back The A-team was a hour- long special...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20053</th>\n",
       "      <td>It is an almost ideal romantic anime! MUST SEE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>Jeremy Northam's characterization of the stutt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "15390  This is simply a good ole fashioned western..n...          1\n",
       "9493   This has to be one of the most beautiful, movi...          1\n",
       "27425  Bring Back The A-team was a hour- long special...          1\n",
       "20053  It is an almost ideal romantic anime! MUST SEE...          1\n",
       "18931  Jeremy Northam's characterization of the stutt...          1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b5aeadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bring Back The A-team was a hour- long special screened on Channel 4 in the UK of last year and hosted by presenter and comedian Justin Lee Collins, the show attempted to track down and reunite the fellow cast members of the A-Team together, for the first time ever on TV. This has been something which has never been attempted before by anyone. Well, not by anyone that I know of, that is.Justin makes a great presenter, and his eccentric personality and humorous banter shone throughout this programme. The attempts he makes in getting hold of the cast members is ever so funny, but also he was very persistent and eager to fulfil this task too, which is a credit to him i'd say. Mind you, he is great on TV anyway- be it by presenting a show such as this, or the Friday Night Project with his co-host, Alan Carr.There were appearances and interviews with Dirk Benedict- the Faceman himself, Dwight Schultz- aka Howling Mad Murdock, Marla Heasley who played Tawnia Baker, Jack Ging aka General 'Bull' Full Bright, the creator of the A-team, Stephen J Cannell and the big man himself, Mr T aka BA Baracus. They were just fascinating to watch and hear what they had to say about the programme that became a global hit during the 80s, as they reminisce and relive the good and bad moments of the show: both during and behind the scenes. Unfortunately, no George Peppard but of course he is already in heaven, understandably and strangely enough no Melinda, who played Amy.I just didn't understand why she wasn't featured in the show. Okay, she was axed after 3 seasons or whatever, but she was the first and original female member of the A-Team- only to be replaced Marla's Tawnia and so it would've been great to see and hear her side to the A-team story, in addition to the other cast members.All in all, Bring Back The A-Team was a great documentary style of show. Perhaps, this could've been spread out more by means of which this could've been a six-part documentary. But nonetheless, this was a great effort on the part of JLC. Recommended\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re #regular expressions library to remove all the html tags\n",
    "clean = re.compile('<.*?>')\n",
    "re.sub(clean , \"\",df.iloc[2].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc763a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean html tags\n",
    "\n",
    "def clean_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean , \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f7e3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(clean_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c40de0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all the text to lower case\n",
    "\n",
    "def convert_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f52a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(convert_lower)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b9f3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove special characters\n",
    "\n",
    "def remove_special(text):\n",
    "    x = ''\n",
    "    \n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            x = x+i\n",
    "        else:\n",
    "            x = x+ ' '\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb95e4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' thw class ic use of pand s is amazing  '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the remove_special function\n",
    "\n",
    "remove_special(' thw class%ic use of pand@s is amazing!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb14bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_special)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5501c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the stopwords\n",
    "\n",
    "import nltk   #natural language toolkit\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab0f1e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15390</th>\n",
       "      <td>this is simply a good ole fashioned western  n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>this has to be one of the most beautiful  movi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27425</th>\n",
       "      <td>bring back the a team was a hour  long special...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20053</th>\n",
       "      <td>it is an almost ideal romantic anime  must see...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>jeremy northam s characterization of the stutt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38308</th>\n",
       "      <td>this pathetic excuse for a movie doesn t have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37400</th>\n",
       "      <td>half a mystical thriller and half the fracture...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>when i was young  i was a big fan of the naked...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31220</th>\n",
       "      <td>this film is horrible  bad acting  bad writing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37479</th>\n",
       "      <td>offbeat and rather entertaining sleeper concer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "15390  this is simply a good ole fashioned western  n...          1\n",
       "9493   this has to be one of the most beautiful  movi...          1\n",
       "27425  bring back the a team was a hour  long special...          1\n",
       "20053  it is an almost ideal romantic anime  must see...          1\n",
       "18931  jeremy northam s characterization of the stutt...          1\n",
       "...                                                  ...        ...\n",
       "38308  this pathetic excuse for a movie doesn t have ...          0\n",
       "37400  half a mystical thriller and half the fracture...          0\n",
       "1719   when i was young  i was a big fan of the naked...          1\n",
       "31220  this film is horrible  bad acting  bad writing...          0\n",
       "37479  offbeat and rather entertaining sleeper concer...          1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20a42eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AhmadDrobi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to see all the existing stopwords in the data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc091bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    x=[]\n",
    "    for i in text.split():   #splitting the words from the and converting in a list\n",
    "        \n",
    "        if i not in stopwords.words('english'):  #only those words will append in the list which are not in stopwords\n",
    "            x.append(i)\n",
    "    y = x[:] #sending all the data of x into y\n",
    "    x.clear() #clearing x for the next review\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f23f5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84e0cb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15390</th>\n",
       "      <td>[simply, good, ole, fashioned, western, overly...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>[one, beautiful, moving, thought, provoking, f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27425</th>\n",
       "      <td>[bring, back, team, hour, long, special, scree...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20053</th>\n",
       "      <td>[almost, ideal, romantic, anime, must, see, ag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18931</th>\n",
       "      <td>[jeremy, northam, characterization, stuttering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38308</th>\n",
       "      <td>[pathetic, excuse, movie, decent, structure, s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37400</th>\n",
       "      <td>[half, mystical, thriller, half, fractured, fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>[young, big, fan, naked, gun, movies, recently...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31220</th>\n",
       "      <td>[film, horrible, bad, acting, bad, writing, ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37479</th>\n",
       "      <td>[offbeat, rather, entertaining, sleeper, conce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "15390  [simply, good, ole, fashioned, western, overly...          1\n",
       "9493   [one, beautiful, moving, thought, provoking, f...          1\n",
       "27425  [bring, back, team, hour, long, special, scree...          1\n",
       "20053  [almost, ideal, romantic, anime, must, see, ag...          1\n",
       "18931  [jeremy, northam, characterization, stuttering...          1\n",
       "...                                                  ...        ...\n",
       "38308  [pathetic, excuse, movie, decent, structure, s...          0\n",
       "37400  [half, mystical, thriller, half, fractured, fa...          0\n",
       "1719   [young, big, fan, naked, gun, movies, recently...          1\n",
       "31220  [film, horrible, bad, acting, bad, writing, ba...          0\n",
       "37479  [offbeat, rather, entertaining, sleeper, conce...          1\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76482284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform stemming\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89762a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[]\n",
    "def stem_words(text):\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    z=y[:]\n",
    "    y.clear()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f37728d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(stem_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e75c7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining back the words\n",
    "\n",
    "def join_back(list_input):\n",
    "    return \" \".join(list_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f1ff26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(join_back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5a42304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15390    simpli good ole fashion western overli complex...\n",
       "9493     one beauti move thought provok film around goo...\n",
       "27425    bring back team hour long special screen chann...\n",
       "20053    almost ideal romant anim must see age english ...\n",
       "18931    jeremi northam character stutter mild manner b...\n",
       "                               ...                        \n",
       "38308    pathet excus movi decent structur sensibl clos...\n",
       "37400    half mystic thriller half fractur fantasi frag...\n",
       "1719     young big fan nake gun movi recent watch show ...\n",
       "31220    film horribl bad act bad write bad music horri...\n",
       "37479    offbeat rather entertain sleeper concern two d...\n",
       "Name: review, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67826fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,0:1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80a45c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd14054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 1000) \n",
    "#max_features helps in increasing the accuracy of the model, as it takes only this many words for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac2def29",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv.fit_transform(df['review']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7effd94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30c52eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking : some word has been repeated 9 times\n",
    "\n",
    "x[899].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "364f120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd21a260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe161778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89ae8783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set \n",
    "#testing set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.2 , random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad812a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 1000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfa35bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae46fdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a8f3d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cda89dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB , MultinomialNB , BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a473598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = GaussianNB()\n",
    "clf2 = MultinomialNB()\n",
    "clf3 = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4585cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x_train , y_train)\n",
    "clf2.fit(x_train , y_train)\n",
    "clf3.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91086276",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(x_test)\n",
    "y_pred2 = clf2.predict(x_test)\n",
    "y_pred3 = clf3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5eab640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian 0.7975\n",
      "Multinomial 0.837\n",
      "Bernoulli 0.8305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Gaussian' , accuracy_score(y_test , y_pred1))\n",
    "print('Multinomial' , accuracy_score(y_test , y_pred2))\n",
    "print('Bernoulli' , accuracy_score(y_test , y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9e23641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  select Bernoulli Naive Bayes model for the movie review Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5b7d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Bernoulli = pd.DataFrame(y_pred3)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "Bernoulli.to_csv('my_Bernoulli.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9db44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
